{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用例ベース対話システム（非タスク対話）\n",
    "ここでは非タスク対話を対象として、用例ベースの雑談対話システムを作成します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 事前の設定\n",
    "- 特になし"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\inoue\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "c:\\Users\\inoue\\anaconda3\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# 必要なラブラリを読み込む\n",
    "\n",
    "import numpy as np\n",
    "import MeCab\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここでは、下記のような用例ベース対話システムを実装します。フレームを実装します。\n",
    "あらかじめ想定されるユーザ発話とそれに対応するシステム応答のペアを複数用意しておき、ユーザ発話が入力されたら最も近い想定ユーザ発話を検索します。\n",
    "そして、それに対応するシステム応答を出力します。\n",
    "類似度の計算には、コサイン距離を用います。\n",
    "ユーザ発話の表現には、言語理解のようにBag-of-Wordsと、学習済みWord2vecによる文ベクトルを用います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/example.png\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用例データの用意\n",
    "\n",
    "まずは、想定されるユーザ発話とそれに対応するシステム応答のペアデータ（用例データ）を読み込みます。\n",
    "データは data/example-base-data.csvに格納されており、各行が１つのペアデータ、１列目が想定ユーザ発話、２列目がシステム応答です。\n",
    "ついでにMeCabによる単語分割も済ませておきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load from ./data/example-base-data.csv\n",
      "こんにちは -> こんにちは\n",
      "趣味は何ですか -> 趣味はスポーツ観戦です\n",
      "好きな食べ物は何ですか -> りんごです\n",
      "一番安い商品は何ですか -> 一番安いのはもやしです\n",
      "最近食べた料理は何ですか -> 最近食べたのはラーメンです\n",
      "出身はどこですか -> 出身は京都です\n",
      "印象に残っている旅行はなんですか -> 印象に残っているのはヨーロッパ旅行です\n",
      "おはよう -> おはようございます\n",
      "こんばんは -> こんばんは\n",
      "さようなら -> さようなら\n",
      "好きな芸能人は誰ですか -> 好きな芸能人はタモリです\n",
      "好きなスポーツは何ですか -> 好きなスポーツはサッカーです\n",
      "好きな動物は何ですか -> 好きな動物は犬です\n",
      "休日は何をされていますか -> 休日は主に散歩しています\n",
      "仕事は何をしていますか -> 仕事は受付係をしています\n",
      "最近はまっていることは何ですか -> 最近は映画鑑賞にはまっています\n",
      "好きな映画は何ですか -> 好きな映画はスターウォーズです\n",
      "好きなゲームは何ですか -> 好きなゲームはポケモンです\n",
      "好きなポケモンは何ですか -> 好きなポケモンはピカチュウです\n",
      "好きな本は何ですか -> 好きな本は純粋理性批判です\n",
      "好きな小説は何ですか -> 好きな小説は指輪物語です\n",
      "好きな漫画は何ですか -> 好きな漫画はドラえもんです\n",
      "好きなアニメは何ですか -> 好きなアニメはドラゴンボールです\n",
      "おすすめのお店はどこですか -> おすすめのお店はサイゼリアです\n",
      "得意な料理は何ですか -> チャーハンが得意料理です\n",
      "好きな教科は何ですか -> 好きな教科は数学です\n",
      "おすすめの観光地はどこですか -> おすすめは清水寺です\n",
      "おすすめのお土産は何ですか -> おすすめは八つ橋です\n",
      "好きなボードゲームは何ですか -> カタンです\n",
      "好きな数字は何ですか -> 好きな数字は1です\n",
      "印象に残っている映画は何ですか -> 印象に残っているのはシャイニングです\n",
      "好きな季節は何ですか -> 好きな季節は夏です\n",
      "嫌いな食べ物は何ですか -> 嫌いな食べ物はキウイです\n",
      "嫌いな動物は何ですか -> 嫌いな動物はカラスです\n",
      "何歳ですか -> 20歳です\n",
      "健康にはどのように気を付けていますか -> 毎日運動するようにしています\n",
      "好きなテレビ番組は何ですか -> 好きなテレビ番組はピタゴラスイッチです\n",
      "好きな絵画は何ですか -> 好きな絵画はモナリザです\n",
      "好きな芸術家は誰ですか -> 好きな芸術家はフェルメールです\n",
      "おすすめの美術館はどこですか -> 国立西洋美術館です\n",
      "好きなの博物館はどこですか -> 京都市博物館です\n",
      "好きな魚は何ですか -> 好きな魚はマグロです\n",
      "本はどこで購入しますか -> 本は大型書店で購入します\n",
      "好きな喫茶店はどこですか -> 好きな喫茶店はスタバです\n",
      "好きなお祭りは何ですか -> 好きな祭りは祇園祭です\n",
      "好きな天気は何ですか -> 好きな天気は雪です\n",
      "好きな元素は何ですか -> 好きな元素は水素です\n",
      "好きな数式は何ですか -> 好きな数式はオイラーの公式です\n",
      "好きなプログラミング言語は何ですか -> 好きなプログラミング言語はPythonです\n",
      "明日の天気は何ですか -> 明日は雨です\n",
      "明日の予定を教えてください -> 明日は2時からミーティングです\n",
      "最近のマイブームを教えてください -> 最近のマイブームは御朱印集めです\n",
      "最近のトレンドを教えてください -> 最近のトレンドは鍋です\n",
      "一番おすすめの商品は何ですか -> おすすめはボールペンです\n",
      "絵の上達方法を教えてください -> 絵の上達のコツはトレースです\n",
      "対話の仕方を教えてください -> 丁寧な言葉で話しかけてください\n",
      "研究内容を教えて -> 人間らしい対話システムの研究をしています\n",
      "尊敬している人は誰ですか -> 尊敬しているのはプラトンです\n",
      "この近くで美味しいお店はどこですか -> おすすめは餃子の王将です\n",
      "動画配信は見ますか -> アマゾンプライムを利用しています\n",
      "最近暑いですね -> 私は暑いのは苦手です\n",
      "何かスポーツはしていますか -> サイクリングをしています\n",
      "実家はどこですか -> 実家は北海道です\n",
      "普段はどんな音楽を聴いていますか -> 普段は主にクラシックを聴いています\n",
      "最近面白い動画を見ましたか -> 最近見て面白かったのはバックパッカーの世界一周記録です\n",
      "部活動は何をしていましたか -> 陸上部に所属していました\n",
      "陸上では何をしていましたか -> 100メートル走をしていました\n",
      "将来の夢は何ですか -> 将来は飲食店を経営したいと思っています\n",
      "いつからこの仕事をしているのですか -> 3年前からです\n",
      "専攻は何ですか -> 数理科学専攻です\n",
      "普段使っているパソコンは何ですか -> 普段はWindowsを使っています\n",
      "好きな諺は何ですか -> 好きな諺は好きこそものの上手なれです\n",
      "最近読んだ本を教えてください -> 最近読んだのはハリーポッターです\n",
      "今度の休日の予定はありますか -> 今度の休日は登山に行く予定です\n",
      "来週は忙しいですか -> 来週は予定が詰まっています\n",
      "友達は何人いますか -> 10人くらいです\n",
      "夏休みはどのように過ごしましたか -> 家で読書をしていました\n",
      "最近の日本についてどのようにお考えですか -> 希望が見えにくくなっているように感じます\n",
      "最近楽しいですか -> 最近は毎日を充実しています\n",
      "どのように充実しているのですか -> 仕事も趣味もうまく行っているからです\n",
      "おすすめの映画を教えてください -> おすすめの映画はローマの休日です\n",
      "応援しているチームを教えてください -> 応援しているチームは鹿島アントラーズです\n",
      "何人兄弟ですか -> 一人っ子です\n",
      "欠かさず見ているドラマってありますか -> 大河ドラマは毎週見ています\n",
      "その服はどこで買いましたか -> ユニクロで買いました\n",
      "どこに住んでいますか -> 今は大阪に住んでいます\n",
      "職場まではどのように通勤していますか -> 電車で通勤しています\n",
      "お昼は何を食べましたか -> ラーメンを食べました\n",
      "みんなからなんて呼ばれていますか -> みんなからはエリカと呼ばれています\n",
      "最近気になるニュースは何ですか -> コロナ関連のニュースはチェックしています\n",
      "最近コロナで大変ですね -> 私の周りでも皆さん大変そうにしています\n",
      "外出できないのは辛いですね -> 私も旅行ができないのは残念です\n",
      "海外には行ったことはありますか -> イタリア旅行に行ったことはあります\n",
      "おすすめのお菓子は何ですか -> おすすめは金平糖です\n",
      "料理は得意ですか -> 普段は軽い炒め物などをしています\n",
      "一人暮らしですか -> 今は一人で暮らしています\n",
      "普段はどこで食事をしていますか -> よく行くお店は吉野家です\n",
      "この近くで美味しいラーメン屋はありますか -> 大学のすぐ横のラーメン屋がおすすめです\n",
      "学生時代の思い出は何ですか -> みんなで海外旅行に行ったのが思い出です\n",
      "よろしくお願いします -> よろしくお願いします\n"
     ]
    }
   ],
   "source": [
    "# 用例データを読み込む\n",
    "pair_data = []\n",
    "filename = './data/example-base-data.csv'\n",
    "print('Load from %s' % filename)\n",
    "with open(filename, 'r', encoding='utf8') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        u1 = line.split(',')[0].strip()\n",
    "        u2 = line.split(',')[1].strip()\n",
    "        pair_data.append([u1, u2])\n",
    "        \n",
    "        print('%s -> %s' % (u1, u2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['こんにちは']\n",
      "こんにちは\n",
      "['趣味', '何']\n",
      "趣味はスポーツ観戦です\n",
      "['好き', '食べ物', '何']\n",
      "りんごです\n",
      "['一番', '安い', '商品', '何']\n",
      "一番安いのはもやしです\n",
      "['最近', '食べ', '料理', '何']\n",
      "最近食べたのはラーメンです\n",
      "['出身', 'どこ']\n",
      "出身は京都です\n",
      "['印象', '残っ', 'いる', '旅行', 'なん']\n",
      "印象に残っているのはヨーロッパ旅行です\n",
      "['おはよう']\n",
      "おはようございます\n",
      "['こんばんは']\n",
      "こんばんは\n",
      "['さようなら']\n",
      "さようなら\n",
      "['好き', '芸能人', '誰']\n",
      "好きな芸能人はタモリです\n",
      "['好き', 'スポーツ', '何']\n",
      "好きなスポーツはサッカーです\n",
      "['好き', '動物', '何']\n",
      "好きな動物は犬です\n",
      "['休日', '何', 'さ', 'れ', 'い']\n",
      "休日は主に散歩しています\n",
      "['仕事', '何', 'し', 'い']\n",
      "仕事は受付係をしています\n",
      "['最近', 'はまっ', 'いる', 'こと', '何']\n",
      "最近は映画鑑賞にはまっています\n",
      "['好き', '映画', '何']\n",
      "好きな映画はスターウォーズです\n",
      "['好き', 'ゲーム', '何']\n",
      "好きなゲームはポケモンです\n",
      "['好き', 'ポケモン', '何']\n",
      "好きなポケモンはピカチュウです\n",
      "['好き', '本', '何']\n",
      "好きな本は純粋理性批判です\n",
      "['好き', '小説', '何']\n",
      "好きな小説は指輪物語です\n",
      "['好き', '漫画', '何']\n",
      "好きな漫画はドラえもんです\n",
      "['好き', 'アニメ', '何']\n",
      "好きなアニメはドラゴンボールです\n",
      "['おすすめ', '店', 'どこ']\n",
      "おすすめのお店はサイゼリアです\n",
      "['得意', '料理', '何']\n",
      "チャーハンが得意料理です\n",
      "['好き', '教科', '何']\n",
      "好きな教科は数学です\n",
      "['おすすめ', '観光', '地', 'どこ']\n",
      "おすすめは清水寺です\n",
      "['おすすめ', '土産', '何']\n",
      "おすすめは八つ橋です\n",
      "['好き', 'ボード', 'ゲーム', '何']\n",
      "カタンです\n",
      "['好き', '数字', '何']\n",
      "好きな数字は1です\n",
      "['印象', '残っ', 'いる', '映画', '何']\n",
      "印象に残っているのはシャイニングです\n",
      "['好き', '季節', '何']\n",
      "好きな季節は夏です\n",
      "['嫌い', '食べ物', '何']\n",
      "嫌いな食べ物はキウイです\n",
      "['嫌い', '動物', '何']\n",
      "嫌いな動物はカラスです\n",
      "['何', '歳']\n",
      "20歳です\n",
      "['健康', 'よう', '気', '付け', 'い']\n",
      "毎日運動するようにしています\n",
      "['好き', 'テレビ', '番組', '何']\n",
      "好きなテレビ番組はピタゴラスイッチです\n",
      "['好き', '絵画', '何']\n",
      "好きな絵画はモナリザです\n",
      "['好き', '芸術', '家', '誰']\n",
      "好きな芸術家はフェルメールです\n",
      "['おすすめ', '美術館', 'どこ']\n",
      "国立西洋美術館です\n",
      "['好き', '博物館', 'どこ']\n",
      "京都市博物館です\n",
      "['好き', '魚', '何']\n",
      "好きな魚はマグロです\n",
      "['本', 'どこ', '購入', 'し']\n",
      "本は大型書店で購入します\n",
      "['好き', '喫茶店', 'どこ']\n",
      "好きな喫茶店はスタバです\n",
      "['好き', '祭り', '何']\n",
      "好きな祭りは祇園祭です\n",
      "['好き', '天気', '何']\n",
      "好きな天気は雪です\n",
      "['好き', '元素', '何']\n",
      "好きな元素は水素です\n",
      "['好き', '数式', '何']\n",
      "好きな数式はオイラーの公式です\n",
      "['好き', 'プログラミング', '言語', '何']\n",
      "好きなプログラミング言語はPythonです\n",
      "['明日', '天気', '何']\n",
      "明日は雨です\n",
      "['明日', '予定', '教え', 'ください']\n",
      "明日は2時からミーティングです\n",
      "['最近', 'マイ', 'ブーム', '教え', 'ください']\n",
      "最近のマイブームは御朱印集めです\n",
      "['最近', 'トレンド', '教え', 'ください']\n",
      "最近のトレンドは鍋です\n",
      "['一番', 'おすすめ', '商品', '何']\n",
      "おすすめはボールペンです\n",
      "['絵', '上達', '方法', '教え', 'ください']\n",
      "絵の上達のコツはトレースです\n",
      "['対話', '仕方', '教え', 'ください']\n",
      "丁寧な言葉で話しかけてください\n",
      "['研究', '内容', '教え']\n",
      "人間らしい対話システムの研究をしています\n",
      "['尊敬', 'し', 'いる', '人', '誰']\n",
      "尊敬しているのはプラトンです\n",
      "['近く', '美味しい', '店', 'どこ']\n",
      "おすすめは餃子の王将です\n",
      "['動画', '配信', '見']\n",
      "アマゾンプライムを利用しています\n",
      "['最近', '暑い']\n",
      "私は暑いのは苦手です\n",
      "['何', 'スポーツ', 'し', 'い']\n",
      "サイクリングをしています\n",
      "['実家', 'どこ']\n",
      "実家は北海道です\n",
      "['普段', '音楽', '聴い', 'い']\n",
      "普段は主にクラシックを聴いています\n",
      "['最近', '面白い', '動画', '見']\n",
      "最近見て面白かったのはバックパッカーの世界一周記録です\n",
      "['部', '活動', '何', 'し', 'い']\n",
      "陸上部に所属していました\n",
      "['陸上', '何', 'し', 'い']\n",
      "100メートル走をしていました\n",
      "['将来', '夢', '何']\n",
      "将来は飲食店を経営したいと思っています\n",
      "['いつ', '仕事', 'し', 'いる', 'の']\n",
      "3年前からです\n",
      "['専攻', '何']\n",
      "数理科学専攻です\n",
      "['普段', '使っ', 'いる', 'パソコン', '何']\n",
      "普段はWindowsを使っています\n",
      "['好き', '諺', '何']\n",
      "好きな諺は好きこそものの上手なれです\n",
      "['最近', '読ん', '本', '教え', 'ください']\n",
      "最近読んだのはハリーポッターです\n",
      "['今度', '休日', '予定', 'あり']\n",
      "今度の休日は登山に行く予定です\n",
      "['来週', '忙しい']\n",
      "来週は予定が詰まっています\n",
      "['友達', '何', '人', 'い']\n",
      "10人くらいです\n",
      "['夏休み', 'よう', '過ごし']\n",
      "家で読書をしていました\n",
      "['最近', '日本', 'よう', '考え']\n",
      "希望が見えにくくなっているように感じます\n",
      "['最近', '楽しい']\n",
      "最近は毎日を充実しています\n",
      "['よう', '充実', 'し', 'いる', 'の']\n",
      "仕事も趣味もうまく行っているからです\n",
      "['おすすめ', '映画', '教え', 'ください']\n",
      "おすすめの映画はローマの休日です\n",
      "['応援', 'し', 'いる', 'チーム', '教え', 'ください']\n",
      "応援しているチームは鹿島アントラーズです\n",
      "['何', '人', '兄弟']\n",
      "一人っ子です\n",
      "['欠かさ', '見', 'いる', 'ドラマ', 'あり']\n",
      "大河ドラマは毎週見ています\n",
      "['服', 'どこ', '買い']\n",
      "ユニクロで買いました\n",
      "['どこ', '住ん', 'い']\n",
      "今は大阪に住んでいます\n",
      "['職場', 'よう', '通勤', 'し', 'い']\n",
      "電車で通勤しています\n",
      "['お昼', '何', '食べ']\n",
      "ラーメンを食べました\n",
      "['みんな', '呼ば', 'れ', 'い']\n",
      "みんなからはエリカと呼ばれています\n",
      "['最近', '気', 'なる', 'ニュース', '何']\n",
      "コロナ関連のニュースはチェックしています\n",
      "['最近', 'コロナ', '大変']\n",
      "私の周りでも皆さん大変そうにしています\n",
      "['外出', 'でき', 'の', '辛い']\n",
      "私も旅行ができないのは残念です\n",
      "['海外', '行っ', 'こと', 'あり']\n",
      "イタリア旅行に行ったことはあります\n",
      "['おすすめ', 'お菓子', '何']\n",
      "おすすめは金平糖です\n",
      "['料理', '得意']\n",
      "普段は軽い炒め物などをしています\n",
      "['一人暮らし']\n",
      "今は一人で暮らしています\n",
      "['普段', 'どこ', '食事', 'し', 'い']\n",
      "よく行くお店は吉野家です\n",
      "['近く', '美味しい', 'ラーメン', '屋', 'あり']\n",
      "大学のすぐ横のラーメン屋がおすすめです\n",
      "['学生', '時代', '思い出', '何']\n",
      "みんなで海外旅行に行ったのが思い出です\n",
      "['お願い', 'し']\n",
      "よろしくお願いします\n"
     ]
    }
   ],
   "source": [
    "# 各発話をMeCabで分割しておき、名詞・形容詞・動詞・感動詞のみを扱う\n",
    "def parse_mecab(sentence):\n",
    "    \n",
    "    m = MeCab.Tagger (\"\")\n",
    "    d_list = m.parse(sentence).strip().split('\\n')\n",
    "    \n",
    "    u = []\n",
    "    for d in d_list:\n",
    "        \n",
    "        if d.strip() == 'EOS':\n",
    "            break\n",
    "        \n",
    "        if len(d.split('\\t')) == 2:\n",
    "            word = d.split('\\t')[0]\n",
    "            pos = d.split('\\t')[1].split(',')[0]\n",
    "        else:\n",
    "            word = d.split('\\t')[0]\n",
    "            pos = d.split('\\t')[4].split('-')[0]\n",
    "        \n",
    "        if pos in ['名詞', '形容詞', '動詞', '感動詞']:\n",
    "            u.append(word)\n",
    "    \n",
    "    return u\n",
    "    \n",
    "pair_data_mecab = []\n",
    "m = MeCab.Tagger (\"\")\n",
    "for d in pair_data:\n",
    "    u1 = parse_mecab(d[0])\n",
    "    u2 = d[1]\n",
    "    pair_data_mecab.append([u1, u2])\n",
    "    \n",
    "    print(u1)\n",
    "    print(u2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、想定ユーザ発話を用いてBag-of-Words表現を作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['こんにちは', '趣味', '何', '好き', '食べ物', '一番', '安い', '商品', '最近', '食べ', '料理', '出身', 'どこ', '印象', '残っ', 'いる', '旅行', 'なん', 'おはよう', 'こんばんは', 'さようなら', '芸能人', '誰', 'スポーツ', '動物', '休日', 'さ', 'れ', 'い', '仕事', 'し', 'はまっ', 'こと', '映画', 'ゲーム', 'ポケモン', '本', '小説', '漫画', 'アニメ', 'おすすめ', '店', '得意', '教科', '観光', '地', '土産', 'ボード', '数字', '季節', '嫌い', '歳', '健康', 'よう', '気', '付け', 'テレビ', '番組', '絵画', '芸術', '家', '美術館', '博物館', '魚', '購入', '喫茶店', '祭り', '天気', '元素', '数式', 'プログラミング', '言語', '明日', '予定', '教え', 'ください', 'マイ', 'ブーム', 'トレンド', '絵', '上達', '方法', '対話', '仕方', '研究', '内容', '尊敬', '人', '近く', '美味しい', '動画', '配信', '見', '暑い', '実家', '普段', '音楽', '聴い', '面白い', '部', '活動', '陸上', '将来', '夢', 'いつ', 'の', '専攻', '使っ', 'パソコン', '諺', '読ん', '今度', 'あり', '来週', '忙しい', '友達', '夏休み', '過ごし', '日本', '考え', '楽しい', '充実', '応援', 'チーム', '兄弟', '欠かさ', 'ドラマ', '服', '買い', '住ん', '職場', '通勤', 'お昼', 'みんな', '呼ば', 'なる', 'ニュース', 'コロナ', '大変', '外出', 'でき', '辛い', '海外', '行っ', 'お菓子', '一人暮らし', '食事', 'ラーメン', '屋', '学生', '時代', '思い出', 'お願い'])\n",
      "{'こんにちは': 0, '趣味': 1, '何': 2, '好き': 3, '食べ物': 4, '一番': 5, '安い': 6, '商品': 7, '最近': 8, '食べ': 9, '料理': 10, '出身': 11, 'どこ': 12, '印象': 13, '残っ': 14, 'いる': 15, '旅行': 16, 'なん': 17, 'おはよう': 18, 'こんばんは': 19, 'さようなら': 20, '芸能人': 21, '誰': 22, 'スポーツ': 23, '動物': 24, '休日': 25, 'さ': 26, 'れ': 27, 'い': 28, '仕事': 29, 'し': 30, 'はまっ': 31, 'こと': 32, '映画': 33, 'ゲーム': 34, 'ポケモン': 35, '本': 36, '小説': 37, '漫画': 38, 'アニメ': 39, 'おすすめ': 40, '店': 41, '得意': 42, '教科': 43, '観光': 44, '地': 45, '土産': 46, 'ボード': 47, '数字': 48, '季節': 49, '嫌い': 50, '歳': 51, '健康': 52, 'よう': 53, '気': 54, '付け': 55, 'テレビ': 56, '番組': 57, '絵画': 58, '芸術': 59, '家': 60, '美術館': 61, '博物館': 62, '魚': 63, '購入': 64, '喫茶店': 65, '祭り': 66, '天気': 67, '元素': 68, '数式': 69, 'プログラミング': 70, '言語': 71, '明日': 72, '予定': 73, '教え': 74, 'ください': 75, 'マイ': 76, 'ブーム': 77, 'トレンド': 78, '絵': 79, '上達': 80, '方法': 81, '対話': 82, '仕方': 83, '研究': 84, '内容': 85, '尊敬': 86, '人': 87, '近く': 88, '美味しい': 89, '動画': 90, '配信': 91, '見': 92, '暑い': 93, '実家': 94, '普段': 95, '音楽': 96, '聴い': 97, '面白い': 98, '部': 99, '活動': 100, '陸上': 101, '将来': 102, '夢': 103, 'いつ': 104, 'の': 105, '専攻': 106, '使っ': 107, 'パソコン': 108, '諺': 109, '読ん': 110, '今度': 111, 'あり': 112, '来週': 113, '忙しい': 114, '友達': 115, '夏休み': 116, '過ごし': 117, '日本': 118, '考え': 119, '楽しい': 120, '充実': 121, '応援': 122, 'チーム': 123, '兄弟': 124, '欠かさ': 125, 'ドラマ': 126, '服': 127, '買い': 128, '住ん': 129, '職場': 130, '通勤': 131, 'お昼': 132, 'みんな': 133, '呼ば': 134, 'なる': 135, 'ニュース': 136, 'コロナ': 137, '大変': 138, '外出': 139, 'でき': 140, '辛い': 141, '海外': 142, '行っ': 143, 'お菓子': 144, '一人暮らし': 145, '食事': 146, 'ラーメン': 147, '屋': 148, '学生': 149, '時代': 150, '思い出': 151, 'お願い': 152}\n",
      "154\n"
     ]
    }
   ],
   "source": [
    "# 想定ユーザ発話を用いてBag-of-Words表現を作成する\n",
    "\n",
    "# 学習データの想定ユーザ発話の単語を語彙（カバーする単語）とする\n",
    "word_list = {}\n",
    "\n",
    "for each_pair in pair_data_mecab:\n",
    "    for word in each_pair[0]:\n",
    "        word_list[word] = 1\n",
    "\n",
    "print(word_list.keys())\n",
    "\n",
    "# 単語とそのインデクスを作成する\n",
    "word_index = {}\n",
    "for idx, word in enumerate(word_list.keys()):\n",
    "    word_index[word] = idx\n",
    "\n",
    "print(word_index)\n",
    "\n",
    "# ベクトルの次元数（未知語を扱うためにプラス１）\n",
    "vec_len = len(word_list.keys()) + 1\n",
    "print(vec_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# 単語の系列とBag-of-Words表現を作成するための情報を受け取りベクトルを返す関数を定義\n",
    "# ※言語理解のときと同じ関数\n",
    "def make_bag_of_words(words, vocab, dim, pos_unk):\n",
    "\n",
    "    vec = [0] * dim\n",
    "    for w in words:\n",
    "\n",
    "        # 未知語\n",
    "        if w not in vocab:\n",
    "            vec[pos_unk] = 1\n",
    "        \n",
    "        # 学習データに含まれる単語\n",
    "        else:\n",
    "            vec[vocab[w]] = 1\n",
    "    \n",
    "    return vec\n",
    "\n",
    "# 試しに変換してみる\n",
    "feature_vec = make_bag_of_words(pair_data_mecab[0][0], word_index, vec_len, vec_len-1)\n",
    "print(feature_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 類似度計算\n",
    "\n",
    "次に、類似度を計算する関数を用意します。\n",
    "ここでは、入力ユーザ発話の単語の系列と、用例データを受け取り、入力ユーザ発話に最も類似するシステム応答を返します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 類似度計算\n",
    "# 入力：ユーザ発話の単語の系列と用例データ\n",
    "# 出力：入力ユーザ発話に最も類似するシステム応答\n",
    "def matching_bagofwords(input_data_mecab, pair_data_mecab):\n",
    "    \n",
    "    # コサイン類似度が最も高いものを採用\n",
    "    cos_dist_max = 0.\n",
    "    response = None\n",
    "    \n",
    "    # 用例毎に処理\n",
    "    for pair_each in pair_data_mecab:\n",
    "        \n",
    "        # Bag-of-Words表現に変換\n",
    "        v1 = np.array(make_bag_of_words(input_data_mecab, word_index, vec_len, vec_len-1))\n",
    "        v2 = np.array(make_bag_of_words(pair_each[0], word_index, vec_len, vec_len-1))\n",
    "        \n",
    "        # コサイン類似度を計算\n",
    "        cos_sim = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "        if cos_dist_max < cos_sim:\n",
    "            cos_dist_max = cos_sim\n",
    "            response = pair_each[1]\n",
    "    \n",
    "    return response, cos_dist_max\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## テスト（Bag-of-Words）\n",
    "では、用例ベース対話システムをテストしてみましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2vecの利用\n",
    "次に，特徴量としてBag-of-wordsではなくWord2vecを用いてみます。日本語でも様々な学習済みモデルがありますが、ここでは下記のものを用います。Word2vecは単語間の距離（類似性）を考慮することができるため、Bag-of-wordsよりもより頑健になることが期待されます。\n",
    "\n",
    "- 日本語 Wikipedia エンティティベクトル\n",
    "    - http://www.cl.ecei.tohoku.ac.jp/~m-suzuki/jawiki_vector/\n",
    "    - 最新のモデルをダウンロードして解凍してください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "入力：趣味は何ですか\n",
      "応答：趣味はスポーツ観戦です\n",
      "類似度：1.000\n",
      "\n",
      "入力：最近面白かったものは何ですか\n",
      "応答：最近食べたのはラーメンです\n",
      "類似度：0.577\n"
     ]
    }
   ],
   "source": [
    "# テスト\n",
    "\n",
    "# 入力発話　その１\n",
    "input_data = '趣味は何ですか'\n",
    "input_data_mecab = parse_mecab(input_data)\n",
    "\n",
    "response, cos_dist_max = matching_bagofwords(input_data_mecab, pair_data_mecab)\n",
    "\n",
    "print('入力：%s' % input_data)\n",
    "print('応答：%s' % response)\n",
    "print('類似度：%.3f' % cos_dist_max)\n",
    "print()\n",
    "\n",
    "# 入力発話　その２\n",
    "input_data = '最近面白かったものは何ですか'\n",
    "input_data_mecab = parse_mecab(input_data)\n",
    "\n",
    "response, cos_dist_max = matching_bagofwords(input_data_mecab, pair_data_mecab)\n",
    "\n",
    "print('入力：%s' % input_data)\n",
    "print('応答：%s' % response)\n",
    "print('類似度：%.3f' % cos_dist_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "# 学習済みWord2vecファイルを読み込む\n",
    "model_filename = './data/entity_vector.model.bin'\n",
    "model_w2v = KeyedVectors.load_word2vec_format(model_filename, binary=True)\n",
    "\n",
    "# 単語ベクトルの次元数\n",
    "print(model_w2v.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.14124946e-01 -2.45451868e-01  3.18230629e-01 -2.42564693e-01\n",
      " -1.68483868e-01  1.18045664e+00 -7.67753646e-02  1.78503878e-02\n",
      " -4.62107748e-01 -1.85864642e-01 -1.13828540e-01 -3.55474725e-02\n",
      " -1.10299480e+00  1.73642501e-01  1.47907531e+00  3.82385731e-01\n",
      "  1.00570440e+00 -2.98919212e-02  1.84403554e-01 -4.12021726e-01\n",
      "  1.99040741e-01  4.81746383e-02 -6.42520070e-01 -7.06509352e-01\n",
      "  1.35463178e-01  6.30207583e-02  3.04609854e-02  5.22573948e-01\n",
      " -1.09154820e+00  8.61533821e-01 -1.86385915e-01  7.11009443e-01\n",
      "  7.48171151e-01  7.42576182e-01  1.00709951e+00 -6.53035402e-01\n",
      "  1.04251623e-01 -1.80611953e-01  1.19915617e+00  1.05364037e+00\n",
      "  7.66198158e-01 -7.74398088e-01  1.82870805e-01  6.92205364e-03\n",
      "  7.19385505e-01  9.12522078e-01 -3.59360665e-01 -6.56168461e-01\n",
      "  3.60351093e-02  2.89187372e-01 -9.25456583e-01 -6.83573127e-01\n",
      "  4.35496598e-01  5.24533033e-01  5.94134629e-01  7.08352804e-01\n",
      "  2.84384400e-01 -8.63615870e-01  8.50027978e-01  1.75993371e+00\n",
      "  5.42705320e-02 -5.33843994e-01 -5.64073741e-01 -9.13450122e-02\n",
      " -6.75944388e-01 -1.29258379e-01 -1.54883087e+00  2.61162877e-01\n",
      "  6.01586223e-01  1.14802279e-01 -6.31672502e-01 -6.01792395e-01\n",
      "  2.88727880e-01  6.18768275e-01  3.69242877e-01 -3.98915231e-01\n",
      "  6.49235129e-01  3.79881650e-01 -1.93782032e+00 -5.16539626e-02\n",
      " -8.23393047e-01  9.99701798e-01 -4.78806376e-01 -5.75362854e-02\n",
      "  5.71419075e-02  3.95675957e-01  4.40068185e-01  3.08368932e-02\n",
      "  7.56013870e-01  5.25878072e-01 -2.95625240e-01  4.32287008e-01\n",
      " -8.06769669e-01  8.13021243e-01  7.39987493e-01 -6.92764342e-01\n",
      "  5.43688893e-01 -7.11423755e-01 -1.22533298e+00 -2.33988240e-01\n",
      " -4.44231853e-02 -3.60669166e-01  2.76205868e-01 -2.15593606e-01\n",
      " -2.68526852e-01  4.06020612e-01  4.46622252e-01  1.00969863e+00\n",
      " -8.09731722e-01  7.47158647e-01  3.59868467e-01  3.95280629e-01\n",
      " -1.28985256e-01 -3.14075828e-01  3.57499927e-01 -1.46291828e+00\n",
      " -1.40641785e+00 -2.99625397e-01 -4.37525213e-01 -2.80579090e-01\n",
      "  8.14465642e-01  5.65493464e-01  3.32336396e-01 -9.30834785e-02\n",
      "  3.23773593e-01 -6.89452946e-01 -2.99346089e-01  9.89344120e-01\n",
      " -1.01399255e+00 -1.28722441e+00  1.77882926e-03  3.08530941e-03\n",
      "  2.79395431e-01 -9.48248804e-01  1.44072309e-01 -7.43502378e-01\n",
      " -9.27002132e-01 -4.18998867e-01 -7.77665138e-01 -1.86835796e-01\n",
      "  1.20832503e+00 -4.81085122e-01  5.58720469e-01  1.40799904e+00\n",
      "  1.75680816e-01 -4.47047167e-02  2.60431487e-02  8.53457510e-01\n",
      "  2.35789657e-01  2.54395962e-01  9.27625522e-02 -6.64648652e-01\n",
      " -6.54454082e-02 -8.02989721e-01 -1.10598159e+00 -1.47992268e-01\n",
      " -5.97676635e-01 -3.38134244e-02 -4.93117988e-01 -3.14613521e-01\n",
      "  8.34164441e-01  1.48655623e-01 -3.14001441e-01 -7.92902946e-01\n",
      "  6.41317427e-01 -6.25185668e-01 -4.57854867e-01  2.76374280e-01\n",
      "  1.06785858e+00 -1.15219426e+00 -5.12794375e-01 -2.24066332e-01\n",
      "  2.06299424e-01  1.37439027e-01 -2.21835330e-01 -2.42151469e-02\n",
      " -6.86468065e-01  6.29820049e-01 -5.04120052e-01 -2.61011153e-01\n",
      "  7.94764519e-01 -3.08615446e-01 -1.25724494e-01  2.36070693e-01\n",
      " -6.50020659e-01 -1.20847833e+00  7.27779806e-01  4.24136259e-02\n",
      "  5.19242406e-01  1.38220215e+00  9.89846945e-01  7.17649043e-01\n",
      " -5.99555254e-01  4.71249133e-01 -8.48583162e-01  1.67412102e-01\n",
      "  7.53096044e-01  1.59877092e-02  4.50618684e-01  1.26120484e+00]\n"
     ]
    }
   ],
   "source": [
    "# Word2vecで特徴量を作成する関数を定義\n",
    "# ここでは文内の各単語のWord2vecを足し合わせたものを文ベクトルととして利用する\n",
    "# ※言語理解のときと同じ関数\n",
    "def make_sentence_vec_with_w2v(words, model_w2v):\n",
    "\n",
    "    sentence_vec = np.zeros(model_w2v.vector_size)\n",
    "    num_valid_word = 0\n",
    "    for w in words:\n",
    "        if w in model_w2v:\n",
    "            sentence_vec += model_w2v[w]\n",
    "            num_valid_word += 1\n",
    "    \n",
    "    # 有効な単語数で割\n",
    "    sentence_vec /= num_valid_word\n",
    "    return sentence_vec\n",
    "\n",
    "\n",
    "# 試しに変換してみる\n",
    "feature_vec = make_sentence_vec_with_w2v(pair_data_mecab[0][0], model_w2v)\n",
    "print(feature_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 類似度計算\n",
    "\n",
    "では、類似度を計算する関数のWord2vec版を用意しましょう。\n",
    "入出の仕様は先ほどと同じで、入力ユーザ発話の単語の系列と、用例データを受け取り、入力ユーザ発話に最も類似するシステム応答を返します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 類似度計算（Word2vec版）\n",
    "# 入力：ユーザ発話の単語の系列と用例データ\n",
    "# 出力：入力ユーザ発話に最も類似するシステム応答\n",
    "def matching_word2vec(input_data_mecab, pair_data_mecab):\n",
    "    \n",
    "    # コサイン類似度が最も高いものを採用\n",
    "    cos_dist_max = 0.\n",
    "    response = None\n",
    "    \n",
    "    # 用例毎に処理\n",
    "    for pair_each in pair_data_mecab:\n",
    "        \n",
    "        # Bag-of-Words表現に変換\n",
    "        v1 = make_sentence_vec_with_w2v(input_data_mecab, model_w2v)\n",
    "        v2 = make_sentence_vec_with_w2v(pair_each[0], model_w2v)\n",
    "        \n",
    "        # コサイン類似度を計算\n",
    "        cos_sim = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "        if cos_dist_max < cos_sim:\n",
    "            cos_dist_max = cos_sim\n",
    "            response = pair_each[1]\n",
    "    \n",
    "    return response, cos_dist_max\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## テスト（Word2vec）\n",
    "では、Word2vecを用いた用例ベース対話システムをテストしてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "入力：趣味は何ですか\n",
      "応答：趣味はスポーツ観戦です\n",
      "類似度：1.000\n",
      "\n",
      "入力：最近面白かったものは何ですか\n",
      "応答：最近は映画鑑賞にはまっています\n",
      "類似度：0.826\n"
     ]
    }
   ],
   "source": [
    "# テスト\n",
    "\n",
    "# 入力発話　その１\n",
    "input_data = '趣味は何ですか'\n",
    "input_data_mecab = parse_mecab(input_data)\n",
    "\n",
    "response, cos_dist_max = matching_word2vec(input_data_mecab, pair_data_mecab)\n",
    "\n",
    "print('入力：%s' % input_data)\n",
    "print('応答：%s' % response)\n",
    "print('類似度：%.3f' % cos_dist_max)\n",
    "print()\n",
    "\n",
    "# 入力発話　その２\n",
    "input_data = '最近面白かったものは何ですか'\n",
    "input_data_mecab = parse_mecab(input_data)\n",
    "\n",
    "response, cos_dist_max = matching_word2vec(input_data_mecab, pair_data_mecab)\n",
    "\n",
    "print('入力：%s' % input_data)\n",
    "print('応答：%s' % response)\n",
    "print('類似度：%.3f' % cos_dist_max)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "1a2eb5a09c124a414d0c803e7aaa7d348a03abaadc97f67347894a4c53feba33"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
